<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
    <channel>
      <title>Vojtěch Tóth</title>
      <link>https://vojtechtoth.github.io</link>
      <description>Last 10 notes on Vojtěch Tóth</description>
      <generator>Quartz -- quartz.jzhao.xyz</generator>
      <item>
    <title>Welcome to My Blog</title>
    <link>https://vojtechtoth.github.io/</link>
    <guid>https://vojtechtoth.github.io/</guid>
    <description><![CDATA[  Welcome Vojtěch Tóth Computer Science Master&#039;s Student About Me My name is Vojtěch Tóth and this is my personal web page. ]]></description>
    <pubDate>Sat, 14 Feb 2026 22:00:19 GMT</pubDate>
  </item><item>
    <title>Booklist</title>
    <link>https://vojtechtoth.github.io/Blog/Booklist</link>
    <guid>https://vojtechtoth.github.io/Blog/Booklist</guid>
    <description><![CDATA[  Reinforcement Learning:An Introduction (link) Speech and Language Processing (link) An Introduction to Computational Learning Theory (link,lecturer notes) . ]]></description>
    <pubDate>Sat, 14 Feb 2026 21:44:19 GMT</pubDate>
  </item><item>
    <title>Implementing linear layer</title>
    <link>https://vojtechtoth.github.io/Blog/Posts/Implementing-linear-layer</link>
    <guid>https://vojtechtoth.github.io/Blog/Posts/Implementing-linear-layer</guid>
    <description><![CDATA[ Linear layer in artificial neural networks is an implementation of y^T = x^TW + b^T, where y \in \mathbb{R}^{\text{n\_outputs} \times 1} is the layers output, x \in \mathbb{R}^{\text{n\_inputs} \times 1} is an input vector, W \in \mathbb{R}^{\text{n\_inputs} \times \text{n\_outputs}} is the weight m... ]]></description>
    <pubDate>Sat, 14 Feb 2026 21:39:01 GMT</pubDate>
  </item><item>
    <title>Implementing MSE</title>
    <link>https://vojtechtoth.github.io/Blog/Posts/Implementing-MSE</link>
    <guid>https://vojtechtoth.github.io/Blog/Posts/Implementing-MSE</guid>
    <description><![CDATA[ Mean square error is defined as \text{MSE}(Y, \hat Y) = \frac{1}{n} \sum^{n}_{i = 1}{(Y_i - \hat Y_i)^2}, where both Y and \hat Y is a 1D array of values. ]]></description>
    <pubDate>Sat, 14 Feb 2026 21:35:26 GMT</pubDate>
  </item><item>
    <title>Adagrad</title>
    <link>https://vojtechtoth.github.io/Vault/Statistical-machine-learning/Neural-networks/Adagrad</link>
    <guid>https://vojtechtoth.github.io/Vault/Statistical-machine-learning/Neural-networks/Adagrad</guid>
    <description><![CDATA[ SSU. ]]></description>
    <pubDate>Sat, 14 Feb 2026 09:40:36 GMT</pubDate>
  </item><item>
    <title>Injective, Surjective, Bijective</title>
    <link>https://vojtechtoth.github.io/Vault/Calculus/Injective,-Surjective,-Bijective</link>
    <guid>https://vojtechtoth.github.io/Vault/Calculus/Injective,-Surjective,-Bijective</guid>
    <description><![CDATA[ math [Bijection], [Surjection], [Injection] Function f(x): A \rightarrow B is called surjective, when (\forall y \in B)(\exists x \in A)(f(x) = y) Surjectivity means that “every image y has at least one pre-image x“. ]]></description>
    <pubDate>Sat, 14 Feb 2026 09:38:24 GMT</pubDate>
  </item><item>
    <title>Ranking function</title>
    <link>https://vojtechtoth.github.io/Vault/Pokro%C4%8Dil%C3%A1-algoritmizace/Combinatorics/Ranking-function</link>
    <guid>https://vojtechtoth.github.io/Vault/Pokro%C4%8Dil%C3%A1-algoritmizace/Combinatorics/Ranking-function</guid>
    <description><![CDATA[ Definice math A bijection assigning unique number to each element of set S. ]]></description>
    <pubDate>Fri, 13 Feb 2026 22:41:16 GMT</pubDate>
  </item><item>
    <title>Untitled</title>
    <link>https://vojtechtoth.github.io/Vault/Statistical-data-analysis/Untitled</link>
    <guid>https://vojtechtoth.github.io/Vault/Statistical-data-analysis/Untitled</guid>
    <description><![CDATA[  ]]></description>
    <pubDate>Fri, 13 Feb 2026 22:14:31 GMT</pubDate>
  </item><item>
    <title>kernel SVM</title>
    <link>https://vojtechtoth.github.io/Vault/Statistical-machine-learning/Support-vector-machines/kernel-SVM</link>
    <guid>https://vojtechtoth.github.io/Vault/Statistical-machine-learning/Support-vector-machines/kernel-SVM</guid>
    <description><![CDATA[ SSU In its base form, SVM creates a linear bound. ]]></description>
    <pubDate>Wed, 11 Feb 2026 11:18:06 GMT</pubDate>
  </item><item>
    <title>SVM</title>
    <link>https://vojtechtoth.github.io/Vault/Statistical-machine-learning/Support-vector-machines/SVM</link>
    <guid>https://vojtechtoth.github.io/Vault/Statistical-machine-learning/Support-vector-machines/SVM</guid>
    <description><![CDATA[ SSU | [Metoda podpůrných vektorů] Reformulation of the Maximum margin classifier problem into a quadratic program solving (w^*, b^*) = \text{arg} \min_{w \in \mathbb{R}^d, b \in \mathbb{R}} \frac{1}{2}||w||^2 subject to \begin{aligned} \langle x_i, w \rangle+ b \ge +1 \quad i \in \mathcal{I}_+\\ \la... ]]></description>
    <pubDate>Wed, 11 Feb 2026 10:29:42 GMT</pubDate>
  </item>
    </channel>
  </rss>